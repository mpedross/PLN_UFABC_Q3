{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpedross/PLN_UFABC_Q3/blob/main/Atividade_02_PLN_(Grupo_17).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 02 [Extração e Pré-processamento de Dados + Expressões Regulares]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 02** deve ser feita utilizando o **Google Colab** com uma conta\n",
        "sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/83JggUJ1mhgWviEaA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 16/10 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "Giulia Ribeiro de Carvalho - 11019616\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "Manoel Pedro dos Santos Souza - 11202131771"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: ` 04\n",
        "\n",
        "`Segundo capítulo:` 21\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` para identificar ERROS em 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        "Os capítulos devem ser selecionados na seguinte planilha:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**DICA:** Por favor, insira o seu nome ou da sua equipe na ordem definida na planilha. Por exemplo, se a linha correspondente ao o GRUPO 5 já foi preenchida, a próxima equipe (GRUPO 6) deverá ser informada na próxima linha da planilha.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TIPOS DE ERROS**\n",
        "---\n"
      ],
      "metadata": {
        "id": "eD_AJQhrwJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: consulta feita no ChatGPT\n",
        ">\n",
        "\n",
        "Um `programa Python` que utilize `expressões regulares` pode ajudar a identificar vários **tipos de erros** comuns em **livros**, especialmente erros de formatação e problemas relacionados à consistência do texto. Aqui estão alguns exemplos de erros comuns que podem ser identificados usando expressões regulares:\n",
        "\n",
        "* Erros de gramática e ortografia: erros de digitação, concordância verbal e nominal, uso incorreto de pontuação e outros erros gramaticais.\n",
        "\n",
        "* Problemas de formatação: você pode usar expressões regulares para encontrar erros de formatação, como espaços em excesso, tabulações inadequadas ou alinhamentos inconsistentes.\n",
        "\n",
        "* Abreviações e acrônimos: você pode usar expressões regulares para encontrar abreviações ou acrônimos que não foram definidos ou explicados anteriormente no texto.\n",
        "\n",
        "* Citações e referências: expressões regulares podem ser úteis para localizar citações ou referências que precisam de formatação especial.\n",
        "\n",
        "* OUTROS TIPOS DE ERROS: não considerem apenas os tipos de erros citados acima.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Lembre-se de que expressões regulares podem ser poderosas, mas também complexas. Dependendo da complexidade dos erros que você deseja identificar, pode ser necessário ajustar as expressões regulares de acordo com as características específicas do seu texto. Além disso, é importante ter em mente que as expressões regulares podem não ser a melhor ferramenta para todos os tipos de erros em livros, especialmente problemas mais contextuais ou semânticos, que podem exigir abordagens de PLN mais avançadas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gz0DTI0KYmn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuzZnOK0_go4",
        "outputId": "ecfeac2b-4cc8-4dc8-b326-2fb8236c4fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A equipe que **realizar mais testes** e/ou **identificar mais erros** terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30). Os testes e possíveis erros devem ser contabizados de maneira separada.\n",
        "\n",
        ">\n",
        "\n",
        "Além disso, **por se tratar de um livro**, há um teste importante que deve ser feito. Lembre-se que o teste deve ser feito utilizando expressões regulares. A equipe que realizar esse teste, mesmo que o erro não ocorra nos capítulos selecionados, terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30).\n",
        "\n",
        "> A equipe pode considerar outros capítulos do livro para tentar identificar esse tipo de erro.\n",
        "\n",
        "**Se for a mesma equipe, o peso da avaliação será reduzido em 50% (caindo de 40 para 20)**.\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE**: a diminuição no peso da AVALIAÇÃO será aplicado para todos os membros da equipe. Esse critério será aplicado apenas para uma equipe, considerando como critério de desempate a equipe que entregar primeiro a atividade no formulário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install requests\n",
        "!pip install html_parser\n",
        "!pip -U install spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "id": "MBVi8QKrbWtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando bibliotecas\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "\n",
        "#Spacy\n",
        "import spacy\n",
        "from spacy.lang.pt.stop_words import STOP_WORDS\n",
        "\n",
        "#NLTK\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "J26Aq80hF1KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementação de testes - Capítulo 04**"
      ],
      "metadata": {
        "id": "Sq0yF6rUlaTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lendo página HTML do capítulo (evitar executar a célula muitas vezes)\n",
        "\n",
        "cap04 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte3/cap4/cap4.html'\n",
        "cap21 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte9/cap21/cap21.html'\n"
      ],
      "metadata": {
        "id": "bSqBd8_894yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fazendo requisição na página.\n",
        "Importante: Passar o parâmetro de url para o capítulo a ser analisado. Basta descomentar a linha com o capítulo desejado (recomendado reiniciar tempo de execução antes de testar cada url)."
      ],
      "metadata": {
        "id": "oAPVm562PGXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para analisar o capítulo 04, descomentar abaixo:\n",
        "#cap = cap04\n",
        "\n",
        "# Já para analisar o capítulo 21, descomentar abaixo e comentar acima:\n",
        "cap = cap21\n",
        "\n",
        "response = requests.get(cap)\n",
        "\n",
        "\n",
        "# verificar se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    print(f'Requisição realizada com sucesso! Código de status:', response.status_code)\n",
        "else:\n",
        "    # imprimir uma mensagem de erro em caso de falha\n",
        "    print(f'A requisição falhou com código de status {response.status_code}.')\n",
        "\n",
        "\n",
        "decoded_content = response.content.decode(\"utf-8\")\n",
        "soup = BeautifulSoup(decoded_content, \"html.parser\")\n",
        "#print(soup)\n",
        "\n",
        "\n",
        "content = soup.find(class_='content')\n",
        "# text = content.get_text(separator='\\n', strip=True)\n",
        "palavras = [string for string in content.stripped_strings]\n",
        "\n",
        "texto = ' '.join(palavras)"
      ],
      "metadata": {
        "id": "ZmURDNX1PB43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texto)"
      ],
      "metadata": {
        "id": "CAfcrvvNhlHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cf6bb6-2864-47ff-e108-65065cbe6fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21 PLN na Saúde Adriana Pagano Claudia Moro Elisa Terumi Rubel Schneider Lilian Mie Mukai Cintho Yohan Gumiel Publicado em: 26/09/2023 21.1 Introdução A área da saúde é uma das mais importantes em nossas vidas e, nos últimos anos, tem se beneficiado do uso da tecnologia para melhorar o diagnóstico, o tratamento e a gestão de pacientes. A aplicação de Processamento de Linguagem Natural (PLN) tem sido fundamental para avançar nessa área, pois permite a análise de grandes volumes de dados não estruturados gerados em ambientes clínicos ( Turchioe et al., 2022 ) . O domínio da medicina abrange diversos tipos de texto, utilizados para distintas atividades produtoras de significado, que desenvolvemos em nosso convívio social. Chamamos essas atividades de socio-semióticas. Estudos da linguagem baseados em pesquisas antropológicas modelam essas atividades socio-semióticas em oito tipos ( Matthiessen, 2013 ; Matthiessen; Teruya; Wu, 2008 ) . A Figura 21.1 mostra os oito tipos de atividades socio-semióticas e os tipos de texto mais representativos de cada um deles no domínio da medicina. Essas atividades são desenvolvidas por meio de textos escritos e falados, com funções específicas na nossa sociedade. Atividades nas quais a linguagem verbal tem um papel ancilar ou complementar são, por exemplo, a execução de procedimentos cirúrgicos, durante a qual ações podem ser verbalizadas ou não. Figura 21.1: Tipos de texto no domínio da medicina Mas, na grande parte das atividades humanas, a linguagem tem um papel constitutivo. Temos desde atividades que envolvem um uso especializado da linguagem para organizar a produção de conhecimento em tratados de medicina, livros didáticos e artigos acadêmicos, até atividades que envolvem um uso menos especializado, como o compartilhamento de experiências no âmbito privado, nas interações entre pacientes e familiares ou entre participantes de fóruns online sobre cuidados em saúde. Para a atividade de instruir e regular o comportamento, temos textos como bulas de medicamentos, cartilhas, normativas, manuais de instrução de equipamentos. Mesmo no domínio da medicina, há também textos pelos quais é construída uma realidade ficcional, como é o caso de series e filmes que recriam interações em contextos médicos. Uma atividade socio-semiótica muito relevante no domínio da medicina é documentar fatos e experiências, por meio de questionários aplicados ao paciente, registros de exames clínicos e relatos de profissionais da saúde, nos quais são documentadas percepções sobre a saúde do paciente. Esses textos são conhecidos em PLN como narrativas clínicas e abrangem notas de evolução de enfermagem, sumários de alta, boletins médicos, e notas em texto livre em campos próprios do prontuário eletrônico do paciente. Cada um desses tipos de texto pode oferecer informações valiosas a serem obtidas por meio do PLN mais adequado às características do texto. Artigos acadêmicos, por exemplo, podem ser usados para a extração de ontologias, que são estruturas semânticas que permitem uma representação formal de conceitos, suas propriedades e relações. Essas ontologias podem ser usadas para facilitar a compreensão de termos técnicos e complexos em diferentes áreas da saúde, permitindo que as informações sejam compartilhadas de forma mais clara e precisa ( Jiang et al., 2020 ) . Também podemos identificar padrões e relacionamentos entre os dados e a construção de modelos preditivos ( Lee et al., 2019 ) . Narrativas clínicas, por outro lado, são textos não estruturados que oferecem informações valiosas sobre a história do paciente, incluindo seus sintomas, histórico médico, estilo de vida e outras informações relevantes. A mineração desses dados pode ser usada para identificar padrões e relacionamentos entre os dados, permitindo uma melhor compreensão da condição do paciente e a construção de modelos preditivos para prever possíveis complicações ou doenças ( Wu et al., 2018 ) . 21.2 O texto livre em narrativas clínicas Com o advento do Registro Eletrônico de Saúde (RES) 1 , como é denominado no Brasil, ou em inglês, o Electronic Health Record (EHR), a quantidade de dados gerados relativos à atenção aos pacientes aumentou significativamente. Os prontuários eletrônicos podem conter dados estruturados, semiestruturados ou não estruturados, todos eles oferecendo uma grande quantidade de informações sobre o paciente. A mineração desses dados pode ajudar a identificar tendências e padrões em relação a diagnósticos, tratamentos e resultados, permitindo uma melhor gestão do cuidado do paciente e um melhor planejamento da assistência ( Shickel et al., 2017 ) . Os dados clínicos presentes nas narrativas clínicas em texto livre (dados não estruturados) apresentam características únicas que dificultam sua análise e interpretação. Esses dados são frequentemente apresentados em linguagem médica especializada, repleta de termos técnicos, jargões e abreviaturas que podem variar entre os distintos profissionais de saúde. Esses textos também podem conter erros de digitação, ortografia ou gramática, tornando a interpretação ainda mais complexa ( Dalianis, 2018 ) . A Figura 21.2 apresenta um exemplo de narrativa clínica adaptada para fins de ilustração. Nela podemos observar que as informações podem ser estruturadas de acordo com categorias destacadas com cores e rotuladas na legenda da figura. Figura 21.2: Exemplo de narrativa clínica elaborada para fins de ilustração. Na legenda, as categorias de informações que podem ser encontradas neste tipo de texto. No escopo do que chamamos narrativas clínicas, há diferentes tipos de texto, os quais apresentam desafios específicos em termos do tipo de linguagem e também da relevância das informações registradas. Por exemplo, as notas de evolução de enfermagem podem ser mais descritivas e detalhadas do que outros tipos de texto, enquanto os sumários de alta podem fornecer informações importantes sobre a condição atual do paciente e seu histórico de tratamento. Já as notas de ambulatório podem ser mais informais e fragmentadas, o que dificulta sua análise por modelos treinados com outros tipos de texto em outros domínios. Isso demanda a anotação manual de narrativas clínicas de forma contarmos com modelos mais refinados. Como todo processo manual, a anotação de narrativas clínicas requer tempo e recursos, o que dificulta a construção de grandes datasets para treinamento de modelos de PLN. Como resultado, a aplicação de técnicas de aprendizado de máquina em dados clínicos sofre limitações pela disponibilidade de dados anotados manualmente ( Koleck et al., 2019 ) . Uma saída é utilizar modelos genéricos para pré-processamento, sendo a saída avaliada manualmente. Um exemplo deste tipo de trabalho é a anotação do corpus Depclin-Br, que vem sendo desenvolvida por uma equipe de cientistas da computação da PUCPR e de linguistas da Faculdade de Letras da UFMG. Trata-se de um conjunto de narrativas clínicas já anotadas em termos de entidades no domínio clínico e constituindo o corpus SemClinBr ( Oliveira et al., 2022a ) . Uma parte desse corpus foi anotada morfossintaticamente com base num modelo genérico de português e a anotação revisada manualmente ( Oliveira et al., 2022b ) . Essa primeira parte foi utilizada para refinamento do modelo genérico e anotação automática de um segunda parte do corpus . Uma vez concluída a anotação, dados do corpus DepClinBr, anotado com relações de dependência, podem ser minerados e utilizados para caracterizar as entidades nomeadas previamente anotadas no SemClinBr. A Figura 21.3 ilustra a correlação de anotações morfossintáticas e entidades. Figura 21.3: Correlação de anotações morfossintáticas e entidades. A construção de corpora de narrativas clínicas (dados não estruturados) está sujeita a restrições técnicas e regulatórias, que dizem respeito à privacidade de dados. Essa especificidade limita a capacidade de construção de grandes datasets para treinamento de modelos de PLN ( Chen; Chen, 2022 ) . Como foi apontado, para contornar essa limitação, são utilizados modelos genéricos da língua, os quais precisam ser refinados com dados específicos do domínio em um processo de fine-tuning , para melhorar ainda mais sua precisão e relevância ( Lee et al., 2019 ) . A seguir, veremos alguns exemplos de aplicações da PLN em dados clínicos. 21.3 Aplicações de PLN na Saúde 21.3.1 Predição Uma das principais tarefas de PLN na área médica é a predição, que pode ser aplicada em diversas demandas do cuidado em saúde, como diagnóstico, tratamento, evolução, alta médica hospitalar, detecção de quedas, detecção de depressão e outras. Essas demandas envolvem a classificação de dados clínicos, como narrativas de pacientes, prontuários eletrônicos, relatórios médicos e outros dados de saúde, para ajudar os médicos e outros profissionais de saúde a tomar decisões mais precisas. A predição de diagnóstico, por exemplo, pode ajudar a identificar doenças em estágios iniciais, permitindo tratamentos mais eficazes e prevenindo complicações. A predição de tratamento pode ajudar a personalizar o tratamento para cada paciente, maximizando sua eficácia e minimizando efeitos colaterais. A detecção de quedas e depressão pode ajudar a prevenir acidentes e melhorar a qualidade de vida dos pacientes. Em resumo, a tarefa de predição é essencial para a aplicação bem-sucedida de PLN na área de saúde ( Yan; Gustad; Nytrø, 2022 ) . Alguns exemplos de trabalhos envolvendo predição e classificação em textos clínicos em português são ( Gonçalves et al., 2023 ; Santos; Ulbrich; Vieira, 2021 ; Silva et al., 2023 ; Yang et al., 2022 ) . 21.3.2 Desidentificação Um aspecto crucial na aplicação de PLN na área médica é a desidentificação dos dados dos pacientes, associada a processos de anonimização ou pseudonimização. Esta envolve a remoção de informações que possam identificar o paciente, como nome, endereço, número de telefone e outras informações pessoais. A anonimização é necessária para garantir a privacidade dos pacientes e cumprir as regulamentações de proteção de dados, como a Lei Geral de Proteção de Dados (LGPD) no Brasil 2 e a General Data Protection Regulation (GDPR) na União Europeia 3 . A anonimização de dados clínicos é um processo desafiador, uma vez que esses dados contêm informações altamente sensíveis e complexas, como histórico médico, sintomas, exames, tratamentos e outros detalhes que podem identificar um paciente. Portanto, é necessário utilizar técnicas avançadas de PLN, como o uso de modelos de linguagem, para remover as informações sensíveis e garantir a privacidade dos pacientes ( Jones et al., 2020 ) . Existem diversas técnicas que podem ser utilizadas na desidentificação dos dados clínicos, dependendo do tipo de informação que deve ser removida e do nível de anonimização desejado, por exemplo: Substituição de nomes próprios e outros identificadores pessoais por símbolos ou pseudônimos aleatórios; Remoção de informações geográficas específicas, como endereço e CEP; Substituição de datas de nascimento e outras informações temporais por intervalos ou idades aproximadas; Remoção de informações de contato, como números de telefone e endereços de e-mail; Remoção de informações de identificação de instituições, como o nome de hospitais e clínicas. Além dessas técnicas, também é possível utilizar métodos mais avançados de PLN, como a detecção e remoção de termos médicos específicos ou o uso de técnicas de de-identificação baseadas em modelos de linguagem, que tentam preservar a integridade semântica dos dados, mesmo após a remoção ou substituição das informações pessoais. A desidentificação dos pacientes permite que os dados clínicos sejam utilizados para fins de pesquisa e análise, sem comprometer a privacidade dos pacientes. Isso é fundamental no avanço da medicina, permitindo a análise de grandes volumes de dados na descoberta de padrões e tendências em doenças, tratamentos e outros aspectos da saúde ( Liu et al., 2017 ) . Em ( Santos et al., 2021 ) temos um exemplo de trabalho para o português nessa tarefa. 21.3.3 Extração de conceitos clínicos A busca e extração de conceitos clínicos relevantes é uma tarefa essencial na aplicação de PLN na área médica. Essa tarefa envolve a identificação de entidades relevantes nos dados clínicos, como sintomas, diagnósticos, tratamentos, medicamentos e outros termos específicos da área da saúde. Essa identificação geralmente é feita por meio de técnicas de NER (do inglês, Named Entity Recognition ), que permitem a identificação e classificação automática de entidades em textos não estruturados. A Figura 21.4 ilustra um exemplo de entidades do tipo Problema reconhecidas em uma narrativa clínica elaborada para fins de ilustração. Figura 21.4: Exemplo de entidades do tipo Problema (em azul) encontradas em narrativa clínica. Além da identificação de entidades, outras técnicas de PLN também podem ser utilizadas para a busca e extração de conceitos clínicos relevantes, como a detecção de negação e a resolução de ambiguidades. A detecção de negação, por exemplo, é útil para identificar quando um sintoma é negado pelo paciente ou um diagnóstico dado pelo médico nega alguma condição. A precisão na deteççnao de nagação é fundamental para a interpretação dos dados clínicos ( Nath; Lee; Lee, 2022 ) . Outra técnica importante na busca e extração de conceitos clínicos é o mapeamento de terminologia, que consiste na associação dos termos clínicos encontrados nos textos com um conjunto de termos padronizados, como a Classificação Internacional de Doenças (CID) ou o Systemized Nomenclature of Medicine (SNOMED CT). Isso permite uma melhor organização e interpretação dos dados clínicos, facilitando a análise e a tomada de decisão médica ( Fennelly et al., 2021 ) . A busca e extração de conceitos clínicos relevantes é fundamental para a análise de dados clínicos em larga escala, permitindo a identificação de padrões e tendências em doenças, tratamentos e outros aspectos da saúde. Além disso, essas técnicas de PLN também podem ser utilizadas para a construção de sistemas de suporte à decisão médica, que auxiliam os profissionais de saúde na escolha de tratamentos mais adequados para cada paciente ( Demner-Fushman; Chapman; McDonald, 2009 ) . 21.3.4 Relações temporais Uma linha do tempo do paciente é uma representação gráfica que organiza as informações clínicas de um paciente de maneira cronológica. O interesse pela pesquisa em extração de relações temporais provém da característica longitudinal dos dados presentes nos Registros Eletrônicos de Saúde. Esses registros contêm múltiplos textos clínicos referentes ao mesmo paciente, escritos em diferentes momentos ( Gumiel et al., 2021 ) . A extração de relações temporais concentra-se na organização sequencial de menções em um texto, sendo essas menções eventos médicos ou expressões temporais. No contexto clínico, eventos médicos são circunstâncias clínicas de relevância, cujo escopo é delimitado pelo contexto da aplicação. Por exemplo, para a extração de informações significativas para o diagnóstico, pode ser apropriado delimitar eventos como menções a tratamentos passados, sinais, sintomas, medicamentos em uso e exames realizados pelo paciente com os respectivos resultados. Já as expressões temporais envolvem menções de tempo, como a duração de um sintoma ou indicações de quando o paciente realizou determinada cirurgia. É notável que as expressões temporais só têm significado quando associadas a algum evento, enquanto os eventos podem fazer sentido quando relacionados entre si. A fim de extrair essas menções do texto, são empregadas técnicas de Processamento de Linguagem Natural (PLN), como a Reconhecimento de Entidades Nomeadas. A tarefa de NER consiste em identificar e classificar automaticamente eventos e expressões temporais. Com eventos e expressões temporais devidamente identificados, aplica-se a extração de relações temporais, uma técnica de PLN que se concentra na conexão de eventos entre si ou com expressões temporais. Desse modo, cada entidade acaba sendo relacionada a um período de tempo específico. Ao considerar relações temporais no contexto clínico, diversas áreas de pesquisa emergem. Doenças crônicas, por exemplo, apresentam uma natureza longitudinal que torna a temporalidade extremamente relevante, pois existem fluxos de dados do paciente contínuos e extensos, nos quais podem ser extraídos padrões significativos ( Sheikhalishahi et al., 2019 ) . A progressão de uma doença e os eventos a ela associados são registrados cronologicamente, onde certos eventos são relevantes apenas em momentos específicos, como problemas médicos identificados durante um exame físico em uma consulta ambulatorial ou sintomas relatados ( Sheikhalishahi et al., 2019 ) . No caso de tratamento ineficaz de hipertensão com monoterapia, por exemplo, busca-se terapias com medicamentos combinados. Portanto, algumas informações sobre a progressão de doenças podem ser mais facilmente discernidas por meio da extração de relações temporais ( Gumiel et al., 2021 ) . A aplicação prática de uma linha do tempo na área da saúde pode ser utilizada para analisar a evolução do quadro clínico do paciente ao longo do tempo, identificar possíveis tendências e realizar previsões. Além disso, a linha do tempo do paciente pode ser integrada a sistemas de suporte à decisão médica, contribuindo para a seleção de tratamentos mais adequados para cada paciente. 21.3.5 Sumarização A sumarização de evoluções clínicas é uma tarefa de PLN que tem como objetivo extrair as informações mais relevantes de um conjunto de dados clínicos, de forma a produzir uma versão resumida e legível dessas informações. A Figura 21.5 exibe um exemplo fictício de uma narrativa clínica sumarizada. Figura 21.5: Exemplo fictício de uma narrativa clínica sumarizada, na qual as informações mais importantes foram mantidas. Para realizar a sumarização de evoluções clínicas, são utilizadas técnicas de sumarização automática de texto, que podem ser baseadas em abordagens extrativas ou abstrativas. Na abordagem extrativa, as frases mais importantes do texto original são selecionadas e combinadas para formar um resumo. Já na abordagem abstrativa, o resumo é gerado a partir da síntese das informações do texto original, gerando uma nova versão que não necessariamente contém as mesmas palavras e frases do texto original. Para realizar a sumarização de evoluções clínicas, são utilizadas técnicas de processamento de linguagem natural, incluindo NER para identificar as entidades relevantes, PoS ( Part-of-Speech ) para identificar as partes do discurso e gramática do texto e também técnicas de análise sintática e semântica. Essa tarefa de PLN é muito útil para os profissionais da área da saúde, pois permite que eles analisem brevemente as informações mais importantes dos pacientes, como histórico de doenças, exames realizados, tratamentos prescritos, entre outras informações clínicas ( Gulden et al., 2019 ) . 21.4 Para onde estamos caminhando? Embora a tecnologia de PLN na área clínica tenha avançado significativamente nos últimos anos, ainda existem vários desafios a serem superados. Alguns desses desafios incluem: Garantir a qualidade dos dados clínicos utilizados para treinar e testar os modelos de PLN, incluindo a devida anonimização e a padronização dos termos utilizados, assegurando a ética e a privacidade dos dados clínicos; Desenvolver modelos de PLN capazes de lidar com textos clínicos mais complexos e heterogêneos, como notas de enfermagem, laudos médicos e textos escritos por pacientes; Integrar os modelos de PLN em sistemas de informação em saúde existentes, garantindo a interoperabilidade e a segurança dos dados; Garantir a aceitação e a adoção dos modelos de PLN pelos profissionais de saúde, demonstrando sua utilidade e eficácia na prática clínica. É importante destacar que, embora o PLN possa ser útil na análise e interpretação de dados clínicos, ele não pode substituir a experiência e o conhecimento clínico de um médico ou de outros profissionais de saúde. A tecnologia pode ser uma ferramenta valiosa para auxiliar na tomada de decisões clínicas, mas não pode substituir o julgamento clínico humano. Ressalta-se que o desenvolvimento de tecnologias de PLN na área clínica seja visto como uma forma de complementar e melhorar o cuidado ao paciente, e não como uma substituição aos profissionais de saúde. CHEN, A.; CHEN, D. O. Simulation of a machine learning enabled learning health system for risk prediction using synthetic patient data. Scientific Reports , v. 12, n. 1, p. 17917, out. 2022. DALIANIS, H. Characteristics of Patient Records and Clinical Corpora . Em: Clinical Text Mining: Secondary Use of Electronic Patient Records . Cham: Springer International Publishing, 2018. p. 21–34. DEMNER-FUSHMAN, D.; CHAPMAN, W. W.; MCDONALD, C. J. What can natural language processing do for clinical decision support? J Biomed Inform , v. 42, n. 5, p. 760–772, ago. 2009. FENNELLY, O. et al. Use of standardized terminologies in clinical practice: A scoping review. Int J Med Inform , v. 149, p. 104431, fev. 2021. GONÇALVES, T. et al. Clinical Screening Prediction in the Portuguese National Health Service: Data Analysis, Machine Learning Models, Explainability and Meta-Evaluation. Future Internet , v. 15, n. 1, p. 26, 2023. GULDEN, C. et al. Extractive summarization of clinical trial descriptions . International Journal of Medical Informatics , v. 129, p. 114–121, 2019. GUMIEL, Y. B. et al. Temporal Relation Extraction in Clinical Texts: A Systematic Review . v. 54, n. 7, set. 2021. JIANG, S. et al. Multi-Ontology Refined Embeddings (MORE): A hybrid multi-ontology and corpus-based semantic representation model for biomedical concepts . Journal of Biomedical Informatics , v. 111, p. 103581, 2020. JONES, K. H. et al. Toward the Development of Data Governance Standards for Using Clinical Free-Text Data in Health Research: Position Paper. J Med Internet Res , v. 22, n. 6, p. e16760, jun. 2020. KOLECK, T. A. et al. Natural language processing of symptoms documented in free-text narratives of electronic health records: a systematic review. J Am Med Inform Assoc , v. 26, n. 4, p. 364–379, abr. 2019. LEE, J. et al. BioBERT: a pre-trained biomedical language representation model for biomedical text mining . Bioinformatics , v. 36, n. 4, p. 1234–1240, set. 2019. LIU, Z. et al. De-identification of clinical notes via recurrent neural network and conditional random field. J Biomed Inform , v. 75S, p. S34–S42, jun. 2017. MATTHIESSEN, M. C. M. I. Applying systemic functional linguistics in healthcare contexts . Text and Talk , v. 33, n. 4-5, p. 437–447, 19 ago. 2013. MATTHIESSEN, M. C. M. I.; TERUYA, K.; WU, C. Multilingual studies as a multi-dimensional space of interconnected language studies. Em: Meaning in context : strategies for implementing intelligent applications of language studies . [s.l.] Continuum, 2008. p. 146–221. NATH, N.; LEE, S.-H.; LEE, I. NEAR: Named Entity and Attribute Recognition of Clinical Concepts . J. of Biomedical Informatics , v. 130, n. C, jun. 2022. OLIVEIRA, L. E. S. et al. SemClinBr - a multi-institutional and multi-specialty semantically annotated corpus for Portuguese clinical NLP tasks . Journal of Biomedical Semantics , v. 13, n. 1, a2022. OLIVEIRA, L. F. A. DE et al. Challenges In Annotating A Treebank Of Clinical Narratives In Brazilian Portuguese . Computational Processing of the Portuguese Language: 15th International Conference, PROPOR 2022, Fortaleza, Brazil, March 21–23, 2022, Proceedings. Anais ...Berlin, Heidelberg: Springer-Verlag, b2022. Disponível em: < https://doi.org/10.1007/978-3-030-98305-5_9 > SANTOS, H. D. P. D.; ULBRICH, A. H. D. P. S.; VIEIRA, R. Evaluation of a Prescription Outlier Detection System in Hospital’s Pharmacy Services . 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). Anais ...IEEE, 2021. SANTOS, J. et al. De-identification of clinical notes using contextualized language models and a token classifier . Brazilian Conference on Intelligent Systems. Anais ...Springer, 2021. SHEIKHALISHAHI, S. et al. Natural Language Processing of Clinical Notes on Chronic Diseases: Systematic Review. JMIR Med Inform , v. 7, n. 2, p. e12239, abr. 2019. SHICKEL, B. et al. Deep EHR : A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record ( EHR ) Analysis. IEEE J Biomed Health Inform , v. 22, n. 5, p. 1589–1604, out. 2017. SILVA, A. P. DA et al. Risco de queda relacionado a medicamentos em hospitais: abordagem de aprendizado de m á quina. Acta Paulista de Enfermagem , v. 36, 2023. TURCHIOE, M. R. et al. Systematic review of current natural language processing methods and applications in cardiology . Heart , v. 108, n. 12, p. 909–916, 2022. WU, H. et al. SemEHR : A general-purpose semantic search system to surface semantic data from clinical notes for tailored care, trial recruitment, and clinical research. J Am Med Inform Assoc , v. 25, n. 5, p. 530–537, 2018. YAN, M. Y.; GUSTAD, L. T.; NYTRØ, Ø. Sepsis prediction, early detection, and identification using clinical text for machine learning: a systematic review. J Am Med Inform Assoc , v. 29, n. 3, p. 559–575, jan. 2022. YANG, H. et al. Clinical Trial Classification of SNS24 Calls with Neural Networks. Future Internet , v. 14, n. 5, p. 130, 2022. No Sistema Único de Saúde (SUS), as informações dos usuários são coletadas e armazenadas por meio do Prontuário Eletrônico do Cidadão (PEC). Nele, há campos pré-determinados que podem ser preenchidos com texto livre. ↩︎ Lei Geral de Proteção de Dados Pessoais (LGPD), Lei nº 13.709/2018. Disponível em: https://www.gov.br › pt-br › acesso-a-informacao › lgpd ↩︎ Data protection in the EU . Disponível em: https://commission.europa.eu/law/law-topic/data-protection/data-protection-eu_en ↩︎\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para tokenizar o texto utilizando NLTK\n",
        "\n",
        "def nltk_tokenizer(texto):\n",
        "  extract_tokens = word_tokenize(texto)\n",
        "  return extract_tokens\n"
      ],
      "metadata": {
        "id": "5zjzLPT7SeA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para extrair apenas as palavras (excluindo números e pontuação) da lista de tokens\n",
        "def extr_words(lista_tokens):\n",
        "  lst_words = [item for item in lista_tokens if re.match(r'^[A-Za-z]+', item)]\n",
        "  return lst_words\n",
        "\n"
      ],
      "metadata": {
        "id": "WY_g1111S8Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk_tokenizer(texto)\n",
        "\n",
        "#Descomentar a linha abaixo para verificar tokens extraídos do texto\n",
        "#print(f'Tokens:', tokens_cap04)\n",
        "\n",
        "palavras = extr_words(tokens)\n",
        "\n",
        "#print(f'Palavras:', palavras_cap04)\n",
        "#print(len(palavras_cap04))"
      ],
      "metadata": {
        "id": "MM7QMbFkTTdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenzando por sentenças\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentencas = sent_tokenize(texto)\n",
        "\n",
        "for i, sentenca in enumerate(sentencas, 1):\n",
        "    print(f\"Sentença {i}: {sentenca}\")"
      ],
      "metadata": {
        "id": "dYWV8XpZZwYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a35187d-0459-4c49-de67-9c68d736dd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1: 21 PLN na Saúde Adriana Pagano Claudia Moro Elisa Terumi Rubel Schneider Lilian Mie Mukai Cintho Yohan Gumiel Publicado em: 26/09/2023 21.1 Introdução A área da saúde é uma das mais importantes em nossas vidas e, nos últimos anos, tem se beneficiado do uso da tecnologia para melhorar o diagnóstico, o tratamento e a gestão de pacientes.\n",
            "Sentença 2: A aplicação de Processamento de Linguagem Natural (PLN) tem sido fundamental para avançar nessa área, pois permite a análise de grandes volumes de dados não estruturados gerados em ambientes clínicos ( Turchioe et al., 2022 ) .\n",
            "Sentença 3: O domínio da medicina abrange diversos tipos de texto, utilizados para distintas atividades produtoras de significado, que desenvolvemos em nosso convívio social.\n",
            "Sentença 4: Chamamos essas atividades de socio-semióticas.\n",
            "Sentença 5: Estudos da linguagem baseados em pesquisas antropológicas modelam essas atividades socio-semióticas em oito tipos ( Matthiessen, 2013 ; Matthiessen; Teruya; Wu, 2008 ) .\n",
            "Sentença 6: A Figura 21.1 mostra os oito tipos de atividades socio-semióticas e os tipos de texto mais representativos de cada um deles no domínio da medicina.\n",
            "Sentença 7: Essas atividades são desenvolvidas por meio de textos escritos e falados, com funções específicas na nossa sociedade.\n",
            "Sentença 8: Atividades nas quais a linguagem verbal tem um papel ancilar ou complementar são, por exemplo, a execução de procedimentos cirúrgicos, durante a qual ações podem ser verbalizadas ou não.\n",
            "Sentença 9: Figura 21.1: Tipos de texto no domínio da medicina Mas, na grande parte das atividades humanas, a linguagem tem um papel constitutivo.\n",
            "Sentença 10: Temos desde atividades que envolvem um uso especializado da linguagem para organizar a produção de conhecimento em tratados de medicina, livros didáticos e artigos acadêmicos, até atividades que envolvem um uso menos especializado, como o compartilhamento de experiências no âmbito privado, nas interações entre pacientes e familiares ou entre participantes de fóruns online sobre cuidados em saúde.\n",
            "Sentença 11: Para a atividade de instruir e regular o comportamento, temos textos como bulas de medicamentos, cartilhas, normativas, manuais de instrução de equipamentos.\n",
            "Sentença 12: Mesmo no domínio da medicina, há também textos pelos quais é construída uma realidade ficcional, como é o caso de series e filmes que recriam interações em contextos médicos.\n",
            "Sentença 13: Uma atividade socio-semiótica muito relevante no domínio da medicina é documentar fatos e experiências, por meio de questionários aplicados ao paciente, registros de exames clínicos e relatos de profissionais da saúde, nos quais são documentadas percepções sobre a saúde do paciente.\n",
            "Sentença 14: Esses textos são conhecidos em PLN como narrativas clínicas e abrangem notas de evolução de enfermagem, sumários de alta, boletins médicos, e notas em texto livre em campos próprios do prontuário eletrônico do paciente.\n",
            "Sentença 15: Cada um desses tipos de texto pode oferecer informações valiosas a serem obtidas por meio do PLN mais adequado às características do texto.\n",
            "Sentença 16: Artigos acadêmicos, por exemplo, podem ser usados para a extração de ontologias, que são estruturas semânticas que permitem uma representação formal de conceitos, suas propriedades e relações.\n",
            "Sentença 17: Essas ontologias podem ser usadas para facilitar a compreensão de termos técnicos e complexos em diferentes áreas da saúde, permitindo que as informações sejam compartilhadas de forma mais clara e precisa ( Jiang et al., 2020 ) .\n",
            "Sentença 18: Também podemos identificar padrões e relacionamentos entre os dados e a construção de modelos preditivos ( Lee et al., 2019 ) .\n",
            "Sentença 19: Narrativas clínicas, por outro lado, são textos não estruturados que oferecem informações valiosas sobre a história do paciente, incluindo seus sintomas, histórico médico, estilo de vida e outras informações relevantes.\n",
            "Sentença 20: A mineração desses dados pode ser usada para identificar padrões e relacionamentos entre os dados, permitindo uma melhor compreensão da condição do paciente e a construção de modelos preditivos para prever possíveis complicações ou doenças ( Wu et al., 2018 ) .\n",
            "Sentença 21: 21.2 O texto livre em narrativas clínicas Com o advento do Registro Eletrônico de Saúde (RES) 1 , como é denominado no Brasil, ou em inglês, o Electronic Health Record (EHR), a quantidade de dados gerados relativos à atenção aos pacientes aumentou significativamente.\n",
            "Sentença 22: Os prontuários eletrônicos podem conter dados estruturados, semiestruturados ou não estruturados, todos eles oferecendo uma grande quantidade de informações sobre o paciente.\n",
            "Sentença 23: A mineração desses dados pode ajudar a identificar tendências e padrões em relação a diagnósticos, tratamentos e resultados, permitindo uma melhor gestão do cuidado do paciente e um melhor planejamento da assistência ( Shickel et al., 2017 ) .\n",
            "Sentença 24: Os dados clínicos presentes nas narrativas clínicas em texto livre (dados não estruturados) apresentam características únicas que dificultam sua análise e interpretação.\n",
            "Sentença 25: Esses dados são frequentemente apresentados em linguagem médica especializada, repleta de termos técnicos, jargões e abreviaturas que podem variar entre os distintos profissionais de saúde.\n",
            "Sentença 26: Esses textos também podem conter erros de digitação, ortografia ou gramática, tornando a interpretação ainda mais complexa ( Dalianis, 2018 ) .\n",
            "Sentença 27: A Figura 21.2 apresenta um exemplo de narrativa clínica adaptada para fins de ilustração.\n",
            "Sentença 28: Nela podemos observar que as informações podem ser estruturadas de acordo com categorias destacadas com cores e rotuladas na legenda da figura.\n",
            "Sentença 29: Figura 21.2: Exemplo de narrativa clínica elaborada para fins de ilustração.\n",
            "Sentença 30: Na legenda, as categorias de informações que podem ser encontradas neste tipo de texto.\n",
            "Sentença 31: No escopo do que chamamos narrativas clínicas, há diferentes tipos de texto, os quais apresentam desafios específicos em termos do tipo de linguagem e também da relevância das informações registradas.\n",
            "Sentença 32: Por exemplo, as notas de evolução de enfermagem podem ser mais descritivas e detalhadas do que outros tipos de texto, enquanto os sumários de alta podem fornecer informações importantes sobre a condição atual do paciente e seu histórico de tratamento.\n",
            "Sentença 33: Já as notas de ambulatório podem ser mais informais e fragmentadas, o que dificulta sua análise por modelos treinados com outros tipos de texto em outros domínios.\n",
            "Sentença 34: Isso demanda a anotação manual de narrativas clínicas de forma contarmos com modelos mais refinados.\n",
            "Sentença 35: Como todo processo manual, a anotação de narrativas clínicas requer tempo e recursos, o que dificulta a construção de grandes datasets para treinamento de modelos de PLN.\n",
            "Sentença 36: Como resultado, a aplicação de técnicas de aprendizado de máquina em dados clínicos sofre limitações pela disponibilidade de dados anotados manualmente ( Koleck et al., 2019 ) .\n",
            "Sentença 37: Uma saída é utilizar modelos genéricos para pré-processamento, sendo a saída avaliada manualmente.\n",
            "Sentença 38: Um exemplo deste tipo de trabalho é a anotação do corpus Depclin-Br, que vem sendo desenvolvida por uma equipe de cientistas da computação da PUCPR e de linguistas da Faculdade de Letras da UFMG.\n",
            "Sentença 39: Trata-se de um conjunto de narrativas clínicas já anotadas em termos de entidades no domínio clínico e constituindo o corpus SemClinBr ( Oliveira et al., 2022a ) .\n",
            "Sentença 40: Uma parte desse corpus foi anotada morfossintaticamente com base num modelo genérico de português e a anotação revisada manualmente ( Oliveira et al., 2022b ) .\n",
            "Sentença 41: Essa primeira parte foi utilizada para refinamento do modelo genérico e anotação automática de um segunda parte do corpus .\n",
            "Sentença 42: Uma vez concluída a anotação, dados do corpus DepClinBr, anotado com relações de dependência, podem ser minerados e utilizados para caracterizar as entidades nomeadas previamente anotadas no SemClinBr.\n",
            "Sentença 43: A Figura 21.3 ilustra a correlação de anotações morfossintáticas e entidades.\n",
            "Sentença 44: Figura 21.3: Correlação de anotações morfossintáticas e entidades.\n",
            "Sentença 45: A construção de corpora de narrativas clínicas (dados não estruturados) está sujeita a restrições técnicas e regulatórias, que dizem respeito à privacidade de dados.\n",
            "Sentença 46: Essa especificidade limita a capacidade de construção de grandes datasets para treinamento de modelos de PLN ( Chen; Chen, 2022 ) .\n",
            "Sentença 47: Como foi apontado, para contornar essa limitação, são utilizados modelos genéricos da língua, os quais precisam ser refinados com dados específicos do domínio em um processo de fine-tuning , para melhorar ainda mais sua precisão e relevância ( Lee et al., 2019 ) .\n",
            "Sentença 48: A seguir, veremos alguns exemplos de aplicações da PLN em dados clínicos.\n",
            "Sentença 49: 21.3 Aplicações de PLN na Saúde 21.3.1 Predição Uma das principais tarefas de PLN na área médica é a predição, que pode ser aplicada em diversas demandas do cuidado em saúde, como diagnóstico, tratamento, evolução, alta médica hospitalar, detecção de quedas, detecção de depressão e outras.\n",
            "Sentença 50: Essas demandas envolvem a classificação de dados clínicos, como narrativas de pacientes, prontuários eletrônicos, relatórios médicos e outros dados de saúde, para ajudar os médicos e outros profissionais de saúde a tomar decisões mais precisas.\n",
            "Sentença 51: A predição de diagnóstico, por exemplo, pode ajudar a identificar doenças em estágios iniciais, permitindo tratamentos mais eficazes e prevenindo complicações.\n",
            "Sentença 52: A predição de tratamento pode ajudar a personalizar o tratamento para cada paciente, maximizando sua eficácia e minimizando efeitos colaterais.\n",
            "Sentença 53: A detecção de quedas e depressão pode ajudar a prevenir acidentes e melhorar a qualidade de vida dos pacientes.\n",
            "Sentença 54: Em resumo, a tarefa de predição é essencial para a aplicação bem-sucedida de PLN na área de saúde ( Yan; Gustad; Nytrø, 2022 ) .\n",
            "Sentença 55: Alguns exemplos de trabalhos envolvendo predição e classificação em textos clínicos em português são ( Gonçalves et al., 2023 ; Santos; Ulbrich; Vieira, 2021 ; Silva et al., 2023 ; Yang et al., 2022 ) .\n",
            "Sentença 56: 21.3.2 Desidentificação Um aspecto crucial na aplicação de PLN na área médica é a desidentificação dos dados dos pacientes, associada a processos de anonimização ou pseudonimização.\n",
            "Sentença 57: Esta envolve a remoção de informações que possam identificar o paciente, como nome, endereço, número de telefone e outras informações pessoais.\n",
            "Sentença 58: A anonimização é necessária para garantir a privacidade dos pacientes e cumprir as regulamentações de proteção de dados, como a Lei Geral de Proteção de Dados (LGPD) no Brasil 2 e a General Data Protection Regulation (GDPR) na União Europeia 3 .\n",
            "Sentença 59: A anonimização de dados clínicos é um processo desafiador, uma vez que esses dados contêm informações altamente sensíveis e complexas, como histórico médico, sintomas, exames, tratamentos e outros detalhes que podem identificar um paciente.\n",
            "Sentença 60: Portanto, é necessário utilizar técnicas avançadas de PLN, como o uso de modelos de linguagem, para remover as informações sensíveis e garantir a privacidade dos pacientes ( Jones et al., 2020 ) .\n",
            "Sentença 61: Existem diversas técnicas que podem ser utilizadas na desidentificação dos dados clínicos, dependendo do tipo de informação que deve ser removida e do nível de anonimização desejado, por exemplo: Substituição de nomes próprios e outros identificadores pessoais por símbolos ou pseudônimos aleatórios; Remoção de informações geográficas específicas, como endereço e CEP; Substituição de datas de nascimento e outras informações temporais por intervalos ou idades aproximadas; Remoção de informações de contato, como números de telefone e endereços de e-mail; Remoção de informações de identificação de instituições, como o nome de hospitais e clínicas.\n",
            "Sentença 62: Além dessas técnicas, também é possível utilizar métodos mais avançados de PLN, como a detecção e remoção de termos médicos específicos ou o uso de técnicas de de-identificação baseadas em modelos de linguagem, que tentam preservar a integridade semântica dos dados, mesmo após a remoção ou substituição das informações pessoais.\n",
            "Sentença 63: A desidentificação dos pacientes permite que os dados clínicos sejam utilizados para fins de pesquisa e análise, sem comprometer a privacidade dos pacientes.\n",
            "Sentença 64: Isso é fundamental no avanço da medicina, permitindo a análise de grandes volumes de dados na descoberta de padrões e tendências em doenças, tratamentos e outros aspectos da saúde ( Liu et al., 2017 ) .\n",
            "Sentença 65: Em ( Santos et al., 2021 ) temos um exemplo de trabalho para o português nessa tarefa.\n",
            "Sentença 66: 21.3.3 Extração de conceitos clínicos A busca e extração de conceitos clínicos relevantes é uma tarefa essencial na aplicação de PLN na área médica.\n",
            "Sentença 67: Essa tarefa envolve a identificação de entidades relevantes nos dados clínicos, como sintomas, diagnósticos, tratamentos, medicamentos e outros termos específicos da área da saúde.\n",
            "Sentença 68: Essa identificação geralmente é feita por meio de técnicas de NER (do inglês, Named Entity Recognition ), que permitem a identificação e classificação automática de entidades em textos não estruturados.\n",
            "Sentença 69: A Figura 21.4 ilustra um exemplo de entidades do tipo Problema reconhecidas em uma narrativa clínica elaborada para fins de ilustração.\n",
            "Sentença 70: Figura 21.4: Exemplo de entidades do tipo Problema (em azul) encontradas em narrativa clínica.\n",
            "Sentença 71: Além da identificação de entidades, outras técnicas de PLN também podem ser utilizadas para a busca e extração de conceitos clínicos relevantes, como a detecção de negação e a resolução de ambiguidades.\n",
            "Sentença 72: A detecção de negação, por exemplo, é útil para identificar quando um sintoma é negado pelo paciente ou um diagnóstico dado pelo médico nega alguma condição.\n",
            "Sentença 73: A precisão na deteççnao de nagação é fundamental para a interpretação dos dados clínicos ( Nath; Lee; Lee, 2022 ) .\n",
            "Sentença 74: Outra técnica importante na busca e extração de conceitos clínicos é o mapeamento de terminologia, que consiste na associação dos termos clínicos encontrados nos textos com um conjunto de termos padronizados, como a Classificação Internacional de Doenças (CID) ou o Systemized Nomenclature of Medicine (SNOMED CT).\n",
            "Sentença 75: Isso permite uma melhor organização e interpretação dos dados clínicos, facilitando a análise e a tomada de decisão médica ( Fennelly et al., 2021 ) .\n",
            "Sentença 76: A busca e extração de conceitos clínicos relevantes é fundamental para a análise de dados clínicos em larga escala, permitindo a identificação de padrões e tendências em doenças, tratamentos e outros aspectos da saúde.\n",
            "Sentença 77: Além disso, essas técnicas de PLN também podem ser utilizadas para a construção de sistemas de suporte à decisão médica, que auxiliam os profissionais de saúde na escolha de tratamentos mais adequados para cada paciente ( Demner-Fushman; Chapman; McDonald, 2009 ) .\n",
            "Sentença 78: 21.3.4 Relações temporais Uma linha do tempo do paciente é uma representação gráfica que organiza as informações clínicas de um paciente de maneira cronológica.\n",
            "Sentença 79: O interesse pela pesquisa em extração de relações temporais provém da característica longitudinal dos dados presentes nos Registros Eletrônicos de Saúde.\n",
            "Sentença 80: Esses registros contêm múltiplos textos clínicos referentes ao mesmo paciente, escritos em diferentes momentos ( Gumiel et al., 2021 ) .\n",
            "Sentença 81: A extração de relações temporais concentra-se na organização sequencial de menções em um texto, sendo essas menções eventos médicos ou expressões temporais.\n",
            "Sentença 82: No contexto clínico, eventos médicos são circunstâncias clínicas de relevância, cujo escopo é delimitado pelo contexto da aplicação.\n",
            "Sentença 83: Por exemplo, para a extração de informações significativas para o diagnóstico, pode ser apropriado delimitar eventos como menções a tratamentos passados, sinais, sintomas, medicamentos em uso e exames realizados pelo paciente com os respectivos resultados.\n",
            "Sentença 84: Já as expressões temporais envolvem menções de tempo, como a duração de um sintoma ou indicações de quando o paciente realizou determinada cirurgia.\n",
            "Sentença 85: É notável que as expressões temporais só têm significado quando associadas a algum evento, enquanto os eventos podem fazer sentido quando relacionados entre si.\n",
            "Sentença 86: A fim de extrair essas menções do texto, são empregadas técnicas de Processamento de Linguagem Natural (PLN), como a Reconhecimento de Entidades Nomeadas.\n",
            "Sentença 87: A tarefa de NER consiste em identificar e classificar automaticamente eventos e expressões temporais.\n",
            "Sentença 88: Com eventos e expressões temporais devidamente identificados, aplica-se a extração de relações temporais, uma técnica de PLN que se concentra na conexão de eventos entre si ou com expressões temporais.\n",
            "Sentença 89: Desse modo, cada entidade acaba sendo relacionada a um período de tempo específico.\n",
            "Sentença 90: Ao considerar relações temporais no contexto clínico, diversas áreas de pesquisa emergem.\n",
            "Sentença 91: Doenças crônicas, por exemplo, apresentam uma natureza longitudinal que torna a temporalidade extremamente relevante, pois existem fluxos de dados do paciente contínuos e extensos, nos quais podem ser extraídos padrões significativos ( Sheikhalishahi et al., 2019 ) .\n",
            "Sentença 92: A progressão de uma doença e os eventos a ela associados são registrados cronologicamente, onde certos eventos são relevantes apenas em momentos específicos, como problemas médicos identificados durante um exame físico em uma consulta ambulatorial ou sintomas relatados ( Sheikhalishahi et al., 2019 ) .\n",
            "Sentença 93: No caso de tratamento ineficaz de hipertensão com monoterapia, por exemplo, busca-se terapias com medicamentos combinados.\n",
            "Sentença 94: Portanto, algumas informações sobre a progressão de doenças podem ser mais facilmente discernidas por meio da extração de relações temporais ( Gumiel et al., 2021 ) .\n",
            "Sentença 95: A aplicação prática de uma linha do tempo na área da saúde pode ser utilizada para analisar a evolução do quadro clínico do paciente ao longo do tempo, identificar possíveis tendências e realizar previsões.\n",
            "Sentença 96: Além disso, a linha do tempo do paciente pode ser integrada a sistemas de suporte à decisão médica, contribuindo para a seleção de tratamentos mais adequados para cada paciente.\n",
            "Sentença 97: 21.3.5 Sumarização A sumarização de evoluções clínicas é uma tarefa de PLN que tem como objetivo extrair as informações mais relevantes de um conjunto de dados clínicos, de forma a produzir uma versão resumida e legível dessas informações.\n",
            "Sentença 98: A Figura 21.5 exibe um exemplo fictício de uma narrativa clínica sumarizada.\n",
            "Sentença 99: Figura 21.5: Exemplo fictício de uma narrativa clínica sumarizada, na qual as informações mais importantes foram mantidas.\n",
            "Sentença 100: Para realizar a sumarização de evoluções clínicas, são utilizadas técnicas de sumarização automática de texto, que podem ser baseadas em abordagens extrativas ou abstrativas.\n",
            "Sentença 101: Na abordagem extrativa, as frases mais importantes do texto original são selecionadas e combinadas para formar um resumo.\n",
            "Sentença 102: Já na abordagem abstrativa, o resumo é gerado a partir da síntese das informações do texto original, gerando uma nova versão que não necessariamente contém as mesmas palavras e frases do texto original.\n",
            "Sentença 103: Para realizar a sumarização de evoluções clínicas, são utilizadas técnicas de processamento de linguagem natural, incluindo NER para identificar as entidades relevantes, PoS ( Part-of-Speech ) para identificar as partes do discurso e gramática do texto e também técnicas de análise sintática e semântica.\n",
            "Sentença 104: Essa tarefa de PLN é muito útil para os profissionais da área da saúde, pois permite que eles analisem brevemente as informações mais importantes dos pacientes, como histórico de doenças, exames realizados, tratamentos prescritos, entre outras informações clínicas ( Gulden et al., 2019 ) .\n",
            "Sentença 105: 21.4 Para onde estamos caminhando?\n",
            "Sentença 106: Embora a tecnologia de PLN na área clínica tenha avançado significativamente nos últimos anos, ainda existem vários desafios a serem superados.\n",
            "Sentença 107: Alguns desses desafios incluem: Garantir a qualidade dos dados clínicos utilizados para treinar e testar os modelos de PLN, incluindo a devida anonimização e a padronização dos termos utilizados, assegurando a ética e a privacidade dos dados clínicos; Desenvolver modelos de PLN capazes de lidar com textos clínicos mais complexos e heterogêneos, como notas de enfermagem, laudos médicos e textos escritos por pacientes; Integrar os modelos de PLN em sistemas de informação em saúde existentes, garantindo a interoperabilidade e a segurança dos dados; Garantir a aceitação e a adoção dos modelos de PLN pelos profissionais de saúde, demonstrando sua utilidade e eficácia na prática clínica.\n",
            "Sentença 108: É importante destacar que, embora o PLN possa ser útil na análise e interpretação de dados clínicos, ele não pode substituir a experiência e o conhecimento clínico de um médico ou de outros profissionais de saúde.\n",
            "Sentença 109: A tecnologia pode ser uma ferramenta valiosa para auxiliar na tomada de decisões clínicas, mas não pode substituir o julgamento clínico humano.\n",
            "Sentença 110: Ressalta-se que o desenvolvimento de tecnologias de PLN na área clínica seja visto como uma forma de complementar e melhorar o cuidado ao paciente, e não como uma substituição aos profissionais de saúde.\n",
            "Sentença 111: CHEN, A.; CHEN, D. O. Simulation of a machine learning enabled learning health system for risk prediction using synthetic patient data.\n",
            "Sentença 112: Scientific Reports , v. 12, n. 1, p. 17917, out.\n",
            "Sentença 113: 2022.\n",
            "Sentença 114: DALIANIS, H. Characteristics of Patient Records and Clinical Corpora .\n",
            "Sentença 115: Em: Clinical Text Mining: Secondary Use of Electronic Patient Records .\n",
            "Sentença 116: Cham: Springer International Publishing, 2018. p. 21–34.\n",
            "Sentença 117: DEMNER-FUSHMAN, D.; CHAPMAN, W. W.; MCDONALD, C. J.\n",
            "Sentença 118: What can natural language processing do for clinical decision support?\n",
            "Sentença 119: J Biomed Inform , v. 42, n. 5, p. 760–772, ago.\n",
            "Sentença 120: 2009.\n",
            "Sentença 121: FENNELLY, O. et al.\n",
            "Sentença 122: Use of standardized terminologies in clinical practice: A scoping review.\n",
            "Sentença 123: Int J Med Inform , v. 149, p. 104431, fev.\n",
            "Sentença 124: 2021.\n",
            "Sentença 125: GONÇALVES, T. et al.\n",
            "Sentença 126: Clinical Screening Prediction in the Portuguese National Health Service: Data Analysis, Machine Learning Models, Explainability and Meta-Evaluation.\n",
            "Sentença 127: Future Internet , v. 15, n. 1, p. 26, 2023.\n",
            "Sentença 128: GULDEN, C. et al.\n",
            "Sentença 129: Extractive summarization of clinical trial descriptions .\n",
            "Sentença 130: International Journal of Medical Informatics , v. 129, p. 114–121, 2019.\n",
            "Sentença 131: GUMIEL, Y.\n",
            "Sentença 132: B. et al.\n",
            "Sentença 133: Temporal Relation Extraction in Clinical Texts: A Systematic Review .\n",
            "Sentença 134: v. 54, n. 7, set.\n",
            "Sentença 135: 2021.\n",
            "Sentença 136: JIANG, S. et al.\n",
            "Sentença 137: Multi-Ontology Refined Embeddings (MORE): A hybrid multi-ontology and corpus-based semantic representation model for biomedical concepts .\n",
            "Sentença 138: Journal of Biomedical Informatics , v. 111, p. 103581, 2020.\n",
            "Sentença 139: JONES, K. H. et al.\n",
            "Sentença 140: Toward the Development of Data Governance Standards for Using Clinical Free-Text Data in Health Research: Position Paper.\n",
            "Sentença 141: J Med Internet Res , v. 22, n. 6, p. e16760, jun.\n",
            "Sentença 142: 2020.\n",
            "Sentença 143: KOLECK, T. A. et al.\n",
            "Sentença 144: Natural language processing of symptoms documented in free-text narratives of electronic health records: a systematic review.\n",
            "Sentença 145: J Am Med Inform Assoc , v. 26, n. 4, p. 364–379, abr.\n",
            "Sentença 146: 2019.\n",
            "Sentença 147: LEE, J. et al.\n",
            "Sentença 148: BioBERT: a pre-trained biomedical language representation model for biomedical text mining .\n",
            "Sentença 149: Bioinformatics , v. 36, n. 4, p. 1234–1240, set.\n",
            "Sentença 150: 2019.\n",
            "Sentença 151: LIU, Z. et al.\n",
            "Sentença 152: De-identification of clinical notes via recurrent neural network and conditional random field.\n",
            "Sentença 153: J Biomed Inform , v. 75S, p. S34–S42, jun.\n",
            "Sentença 154: 2017.\n",
            "Sentença 155: MATTHIESSEN, M. C. M. I.\n",
            "Sentença 156: Applying systemic functional linguistics in healthcare contexts .\n",
            "Sentença 157: Text and Talk , v. 33, n. 4-5, p. 437–447, 19 ago.\n",
            "Sentença 158: 2013.\n",
            "Sentença 159: MATTHIESSEN, M. C. M. I.; TERUYA, K.; WU, C. Multilingual studies as a multi-dimensional space of interconnected language studies.\n",
            "Sentença 160: Em: Meaning in context : strategies for implementing intelligent applications of language studies .\n",
            "Sentença 161: [s.l.]\n",
            "Sentença 162: Continuum, 2008. p. 146–221.\n",
            "Sentença 163: NATH, N.; LEE, S.-H.; LEE, I.\n",
            "Sentença 164: NEAR: Named Entity and Attribute Recognition of Clinical Concepts .\n",
            "Sentença 165: J. of Biomedical Informatics , v. 130, n. C, jun.\n",
            "Sentença 166: 2022.\n",
            "Sentença 167: OLIVEIRA, L. E. S. et al.\n",
            "Sentença 168: SemClinBr - a multi-institutional and multi-specialty semantically annotated corpus for Portuguese clinical NLP tasks .\n",
            "Sentença 169: Journal of Biomedical Semantics , v. 13, n. 1, a2022.\n",
            "Sentença 170: OLIVEIRA, L. F. A.\n",
            "Sentença 171: DE et al.\n",
            "Sentença 172: Challenges In Annotating A Treebank Of Clinical Narratives In Brazilian Portuguese .\n",
            "Sentença 173: Computational Processing of the Portuguese Language: 15th International Conference, PROPOR 2022, Fortaleza, Brazil, March 21–23, 2022, Proceedings.\n",
            "Sentença 174: Anais ...Berlin, Heidelberg: Springer-Verlag, b2022.\n",
            "Sentença 175: Disponível em: < https://doi.org/10.1007/978-3-030-98305-5_9 > SANTOS, H. D. P. D.; ULBRICH, A. H. D. P. S.; VIEIRA, R. Evaluation of a Prescription Outlier Detection System in Hospital’s Pharmacy Services .\n",
            "Sentença 176: 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM).\n",
            "Sentença 177: Anais ...IEEE, 2021.\n",
            "Sentença 178: SANTOS, J. et al.\n",
            "Sentença 179: De-identification of clinical notes using contextualized language models and a token classifier .\n",
            "Sentença 180: Brazilian Conference on Intelligent Systems.\n",
            "Sentença 181: Anais ...Springer, 2021.\n",
            "Sentença 182: SHEIKHALISHAHI, S. et al.\n",
            "Sentença 183: Natural Language Processing of Clinical Notes on Chronic Diseases: Systematic Review.\n",
            "Sentença 184: JMIR Med Inform , v. 7, n. 2, p. e12239, abr.\n",
            "Sentença 185: 2019.\n",
            "Sentença 186: SHICKEL, B. et al.\n",
            "Sentença 187: Deep EHR : A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record ( EHR ) Analysis.\n",
            "Sentença 188: IEEE J Biomed Health Inform , v. 22, n. 5, p. 1589–1604, out.\n",
            "Sentença 189: 2017.\n",
            "Sentença 190: SILVA, A. P. DA et al.\n",
            "Sentença 191: Risco de queda relacionado a medicamentos em hospitais: abordagem de aprendizado de m á quina.\n",
            "Sentença 192: Acta Paulista de Enfermagem , v. 36, 2023.\n",
            "Sentença 193: TURCHIOE, M. R. et al.\n",
            "Sentença 194: Systematic review of current natural language processing methods and applications in cardiology .\n",
            "Sentença 195: Heart , v. 108, n. 12, p. 909–916, 2022.\n",
            "Sentença 196: WU, H. et al.\n",
            "Sentença 197: SemEHR : A general-purpose semantic search system to surface semantic data from clinical notes for tailored care, trial recruitment, and clinical research.\n",
            "Sentença 198: J Am Med Inform Assoc , v. 25, n. 5, p. 530–537, 2018.\n",
            "Sentença 199: YAN, M. Y.; GUSTAD, L. T.; NYTRØ, Ø. Sepsis prediction, early detection, and identification using clinical text for machine learning: a systematic review.\n",
            "Sentença 200: J Am Med Inform Assoc , v. 29, n. 3, p. 559–575, jan. 2022.\n",
            "Sentença 201: YANG, H. et al.\n",
            "Sentença 202: Clinical Trial Classification of SNS24 Calls with Neural Networks.\n",
            "Sentença 203: Future Internet , v. 14, n. 5, p. 130, 2022.\n",
            "Sentença 204: No Sistema Único de Saúde (SUS), as informações dos usuários são coletadas e armazenadas por meio do Prontuário Eletrônico do Cidadão (PEC).\n",
            "Sentença 205: Nele, há campos pré-determinados que podem ser preenchidos com texto livre.\n",
            "Sentença 206: ↩︎ Lei Geral de Proteção de Dados Pessoais (LGPD), Lei nº 13.709/2018.\n",
            "Sentença 207: Disponível em: https://www.gov.br › pt-br › acesso-a-informacao › lgpd ↩︎ Data protection in the EU .\n",
            "Sentença 208: Disponível em: https://commission.europa.eu/law/law-topic/data-protection/data-protection-eu_en ↩︎\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para stemização das palavras\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(\"portuguese\")\n",
        "\n",
        "#Usando SnowballStemmer\n",
        "def stem_words(lst_palavras):\n",
        "    stem_words_lst = [stemmer.stem(word) for word in lst_palavras]\n",
        "    return stem_words_lst"
      ],
      "metadata": {
        "id": "nluNn1OAshU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words_lst = stem_words(palavras)\n",
        "#print(stem_words_lst)\n",
        "\n",
        "stem_words_df = pd.DataFrame(stem_words_lst, columns=[\"Radicais\"])\n",
        "print(stem_words_df)"
      ],
      "metadata": {
        "id": "dIKnDKKushJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc41df9-ddf9-46c6-fbdf-aec55d950581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Radicais\n",
            "0         pln\n",
            "1          na\n",
            "2        saúd\n",
            "3      adrian\n",
            "4       pagan\n",
            "...       ...\n",
            "3636      the\n",
            "3637       eu\n",
            "3638   dispon\n",
            "3639       em\n",
            "3640    https\n",
            "\n",
            "[3641 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Função para buscar letra minúscula após ponto final no texto"
      ],
      "metadata": {
        "id": "shCfkkBzKBTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padrão para encontrar todas as letras minúsculas após um ponto final\n",
        "\n",
        "def find_lowercase_after_final(text):\n",
        "  pattern = r'\\.\\s+([a-z])\\s+'\n",
        "  pattern_eg = r'\\be\\.g\\s*'\n",
        "\n",
        "  # Procurando o padrão definido acima\n",
        "  pattern_lst = re.finditer(pattern, text)\n",
        "\n",
        "  # Lista para armazenar letras minúsculas e seus respectivos contextos\n",
        "  context_findings = []\n",
        "\n",
        "  for item in pattern_lst:\n",
        "    letter = item.group(1)\n",
        "    start_position = item.start()\n",
        "    end_position = item.end()\n",
        "\n",
        "    # Capturando contexto antes e depois da letra\n",
        "    capt_abrv = text[max(0, start_position - 3):start_position]\n",
        "    context_before = text[max(-1, start_position - 10):start_position]\n",
        "    context_after = text[end_position-1:end_position + 10]\n",
        "\n",
        "    # Identificando se \"e.g\" está presente como abreviação antes da letra minúscula\n",
        "    if not re.search(pattern_eg, capt_abrv):\n",
        "      context_findings.append((letter, context_before, context_after))\n",
        "\n",
        "    data = [{\"Frase com erro\": item[0] + item[1] + item[2]} for item in context_findings]\n",
        "    context_findings_df = pd.DataFrame(data)\n",
        "    return context_findings_df\n",
        "\n",
        "\n",
        "result_lowercase = find_lowercase_after_final(texto)\n",
        "print(result_lowercase) ##Não encontrou nada!\n",
        "\n"
      ],
      "metadata": {
        "id": "mhpLe3TCKP0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b62054-d73f-46d6-b1e5-27a4e04b9edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Remoção de referências para análise do texto"
      ],
      "metadata": {
        "id": "8tJoaEyR6Blv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removendo conteúdo de referências para análise de erros no texto\n",
        "#Importante pois, como as referências tratam-se de títulos, incluí-las em algumas análises trariam falsos erros\n",
        "\n",
        "# Removendo as partes dentro de divs com id contendo \"ref\"\n",
        "for div in soup.find_all('div', id=lambda x: x and 'ref' in x):\n",
        "    div.decompose()\n",
        "\n",
        "# Identificando a seção \"footnotes\" para também removê-la (contém referências)\n",
        "footnotes = soup.find('div', {'class': 'footnotes'})\n",
        "if footnotes:\n",
        "    for elem in footnotes.find_all_next():\n",
        "        elem.decompose()\n",
        "\n",
        "# Obtendo o texto sem as referências\n",
        "without_ref = soup.get_text(separator='\\n', strip=True)\n",
        "\n",
        "#print(without_ref)"
      ],
      "metadata": {
        "id": "FOJUTT6UvwX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Função para encontrar ocorrências de letra maiúscula após dois-pontos (:)"
      ],
      "metadata": {
        "id": "WxJUYnHRhWpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_uppercase(text):\n",
        "    pattern_uppercase = r'([^:]*:\\s*)([A-Z]+)'\n",
        "    findings = re.finditer(pattern_uppercase, text)\n",
        "    context_findings = []\n",
        "\n",
        "    for uppercase in findings:\n",
        "      start_position = uppercase.start()\n",
        "      end_position = uppercase.end()\n",
        "\n",
        "      context_before = text[max(-1, start_position - 15):start_position]\n",
        "      context_after = text[end_position:end_position + 10]\n",
        "      context_findings.append((context_before, uppercase.group(2), context_after))\n",
        "    #return context_findings\n",
        "\n",
        "    data = [{\"Frase com erro\": item[0] + item[1] + item[2]} for item in context_findings]\n",
        "    context_findings_df = pd.DataFrame(data)\n",
        "    return context_findings_df\n",
        "\n",
        "\n",
        "result_uppercase = find_uppercase(without_ref)\n",
        "print(result_uppercase)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7BTsFlsp99I",
        "outputId": "abe1c51a-46b3-4895-9d15-875a2afbd803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Frase com erro\n",
            "0  l\\nPublicado em:Tipos de te\n",
            "1  \\nFigura 21.1: TExemplo de \n",
            "2  \\nFigura 21.2: ECorrelação \n",
            "3  \\nFigura 21.3: CSubstituiçã\n",
            "4   por exemplo:\\nSExemplo de \n",
            "5  \\nFigura 21.4: EExemplo fic\n",
            "6  \\nFigura 21.5: EGarantir a \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Função para encontrar uso inadequado de cedilha (ç)"
      ],
      "metadata": {
        "id": "LxCKSheP0Ayz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Texto inteiro"
      ],
      "metadata": {
        "id": "kK1zyKiI6bWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_cedilha(text):\n",
        "    pattern_cedilha = r'ç(^[eou])'\n",
        "    findings = re.finditer(pattern_cedilha, text)\n",
        "    context_findings = []\n",
        "\n",
        "    for cedilha in findings:\n",
        "      start_position = cedilha.start()\n",
        "      end_position = cedilha.end()\n",
        "\n",
        "      context_before = text[max(-1, start_position - 15):start_position]\n",
        "      context_after = text[end_position-1:end_position + 10]\n",
        "      context_findings.append((context_before, cedilha.group(1), context_after))\n",
        "    #return context_findings\n",
        "\n",
        "    data = [{\"Frase com erro\": item[0] + item[1] + item[2]} for item in context_findings]\n",
        "    context_findings_df = pd.DataFrame(data)\n",
        "    return context_findings_df\n",
        "\n",
        "\n",
        "result_cedilha = find_cedilha(texto)\n",
        "print(result_cedilha) ##Não encontrou nada!\n",
        "\n"
      ],
      "metadata": {
        "id": "NNV7n87G0Acj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af56c0e0-35f2-4329-ee26-c1f8ec6bd865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Buscando na lista de palavras"
      ],
      "metadata": {
        "id": "rEOa7DsE6gJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_cedilha_2(words):\n",
        "    pattern_cedilha = r'ç(^[eou])'\n",
        "    #findings = re.match(pattern_cedilha, words)\n",
        "    strings_of_text = list(filter(lambda x: re.match(pattern_cedilha, x), words))\n",
        "    print(strings_of_text)\n",
        "\n",
        "\n",
        "\n",
        "find_cedilha_2(palavras) #(Não achou nada também)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSmOZpNP2cE8",
        "outputId": "c65ddca4-f3f6-491c-a120-a1bc476b8d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Função para identificar uso indevido de hífen (-)"
      ],
      "metadata": {
        "id": "Wt3YdLGu_eJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_hifen(text):\n",
        "    pattern_hifen_rs = r'([aeiouAEIOU])-(?!se\\b)([rs])' #Remover as letras maiúsculas do \"rs\" para evitar o retorno de nomes próprios; usar o lookahead no -se para evitar retornar o sufixo como em \"torna-se\"\n",
        "    #pattern_hifen_ih = r'[a-z](ii|ih)[a-z]'\n",
        "    pattern_hifen_ih = r'(ii|ih)[a-z]'\n",
        "    findings_rs = re.finditer(pattern_hifen_rs, text)\n",
        "    findings_ih = re.finditer(pattern_hifen_ih, text)\n",
        "    context_findings = []\n",
        "\n",
        "    for (hifen_incorreto_rs, hifen_incorreto_ih) in zip(findings_rs, findings_ih):\n",
        "\n",
        "        start_position_rs = hifen_incorreto_rs.start()\n",
        "        end_position_rs = hifen_incorreto_rs.end()\n",
        "\n",
        "        context_before_rs = text[max(0, start_position_rs - 8):start_position_rs]\n",
        "        context_after_rs = text[end_position_rs:end_position_rs + 10]\n",
        "        context_findings.append((context_before_rs, hifen_incorreto_rs.group(), context_after_rs))\n",
        "\n",
        "        start_position_ih = hifen_incorreto_ih.start()\n",
        "        end_position_ih = hifen_incorreto_ih.end()\n",
        "\n",
        "        context_before_ih = text[max(0, start_position_ih - 8):start_position_ih]\n",
        "        context_after_ih = text[end_position_ih:end_position_ih + 10]\n",
        "        context_findings.append((context_before_ih, hifen_incorreto_ih.group(), context_after_ih))\n",
        "\n",
        "    data = [{\"Frase com erro\": item[0] + item[1] + item[2]} for item in context_findings]\n",
        "    context_findings_df = pd.DataFrame(data)\n",
        "    return context_findings_df\n",
        "\n",
        "\n",
        "result_hifen = find_hifen(texto)\n",
        "print(result_hifen)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c36vAcgj7Ed3",
        "outputId": "67bcaf67-2ce8-4387-8e1d-1426613d8647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Função para buscar espaço após parêntese de abertura ( exemplo) ou antes de parêntese de fechamento (exemplo )."
      ],
      "metadata": {
        "id": "MUZbjR4az8mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_space_prts(text):\n",
        "    pattern_space_before = r'\\(\\s+'\n",
        "    pattern_space_after = r'\\s+\\)'\n",
        "    findings_before = re.finditer(pattern_space_before, text)\n",
        "    findings_after = re.finditer(pattern_space_after, text)\n",
        "    context_findings = []\n",
        "\n",
        "    for (space_before, space_after) in zip(findings_before, findings_after):\n",
        "\n",
        "        start_position_before = space_before.start()\n",
        "        end_position_before = space_before.end()\n",
        "\n",
        "        context_before_bf = text[max(0, start_position_before - 8):start_position_before]\n",
        "        context_after_af = text[end_position_before:end_position_before + 10]\n",
        "        context_findings.append((context_before_bf, space_before.group(), context_after_af))\n",
        "\n",
        "        start_position_after = space_after.start()\n",
        "        end_position_after = space_after.end()\n",
        "\n",
        "        context_before_af = text[max(0, start_position_after - 8):start_position_after]\n",
        "        context_after_af = text[end_position_after:end_position_after + 10]\n",
        "        context_findings.append((context_before_af, space_after.group(), context_after_af))\n",
        "\n",
        "\n",
        "    data = [{\"Frase com erro\": item[0] + item[1] + item[2]} for item in context_findings]\n",
        "    context_findings_df = pd.DataFrame(data)\n",
        "    return context_findings_df\n",
        "\n",
        "\n",
        "result_space_prts = find_space_prts(texto)\n",
        "print(result_space_prts)"
      ],
      "metadata": {
        "id": "GAZVqAYAzG7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Função para identificar problema de formatação (espaços em excesso)"
      ],
      "metadata": {
        "id": "sWvs3TUpdJui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Capturando dois ou mais espaços em branco\n",
        "\n",
        "def find_excess_spaces_with_context(soup):\n",
        "\n",
        "    text_nodes = soup.find_all(text=True)\n",
        "\n",
        "    excess_space_pattern = re.compile(r'\\s{2,}')\n",
        "    context_findings = []\n",
        "\n",
        "    for node in text_nodes:\n",
        "        matches = list(excess_space_pattern.finditer(node))\n",
        "        for match in matches:\n",
        "            start_position = match.start()\n",
        "            end_position = match.end()\n",
        "\n",
        "            context_before = node[max(0, start_position - 10):start_position]\n",
        "            context_after = node[end_position:end_position + 10]\n",
        "            context_findings.append((context_before, match.group(), context_after))\n",
        "\n",
        "    data = [{\"Frase com erro\": item[0] + item[1] + item[2]} for item in context_findings]\n",
        "    context_findings_df = pd.DataFrame(data)\n",
        "    return context_findings_df\n",
        "\n",
        "decoded_content = response.content.decode(\"utf-8\")\n",
        "soup = BeautifulSoup(decoded_content, \"html.parser\")\n",
        "\n",
        "result_excess_spaces_df = find_excess_spaces_with_context(soup)\n",
        "print(result_excess_spaces_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-gy8XvGetci",
        "outputId": "68dded9e-f7f9-4aa9-e942-20bdf66564a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Frase com erro\n",
            "0       tural - 21  PLN na Saú\n",
            "1     eckbox\"] {\\n  width: 0.8\n",
            "2     th: 0.8em;\\n  margin: 0 \n",
            "3    es/4556 */ \\n  vertical-a\n",
            "4     sl-entry {\\n  clear: bot\n",
            "..                         ...\n",
            "295     });\\n    }\\n  }\\n});\\n\n",
            "296                           \n",
            "297                           \n",
            "298            \\n       \\n    \n",
            "299            \\n       \\n    \n",
            "\n",
            "[300 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-6155dce12d16>:5: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  text_nodes = soup.find_all(text=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Contagem total de erros\n",
        "\n",
        "A função abaixo reúne todos os erros encontrados nas funções desenvolvidas acima em um único dataframe"
      ],
      "metadata": {
        "id": "mEs4sbL86-tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chamando todas as funções criadas anteriormente\n",
        "\n",
        "# 1. Função para buscar letra minúscula após ponto final no texto\n",
        "\n",
        "result_lowercase = find_lowercase_after_final(texto)\n",
        "\n",
        "# 2. Função para encontrar ocorrências de letra maiúscula após dois-pontos (:) - usar texto sem referências (without_ref)\n",
        "\n",
        "result_uppercase = find_uppercase(without_ref)\n",
        "\n",
        "# 3. Função para encontrar uso inadequado de cedilha (ç)\n",
        "\n",
        "result_cedilha = find_cedilha(texto)\n",
        "\n",
        "# 4. Função para identificar uso indevido de hífen (-)\n",
        "\n",
        "result_hifen = find_hifen(texto)\n",
        "\n",
        "# 5. Função para buscar espaço após parêntese de abertura ( exemplo) ou antes de parêntese de fechamento (exemplo ).\n",
        "\n",
        "result_space_prts = find_space_prts(texto)\n",
        "\n",
        "# 6. Função para identificar problema de formatação (espaços em excesso)\n",
        "\n",
        "result_excess_spaces_df = find_excess_spaces_with_context(soup)"
      ],
      "metadata": {
        "id": "TNxAajpyDXe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c490b4c-f817-41b6-ffee-74482a3b72b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-6155dce12d16>:5: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  text_nodes = soup.find_all(text=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Como uma função pode retornar um dataframe vazio ou não dependendo do texto aplicado, abaixo estamos\n",
        "#tratando o resultado inclusive em caso de vazio (empty)\n",
        "\n",
        "errors_dict = {\n",
        "    'Minúscula após ponto final': result_lowercase[result_lowercase.columns[0]] if result_lowercase is not None and not result_lowercase[result_lowercase.columns[0]].empty else None,\n",
        "    'Maiúscula após dois-pontos': result_uppercase[result_uppercase.columns[0]] if not result_uppercase.empty else None,\n",
        "    'Uso inadequado cedilha': result_cedilha[result_cedilha.columns[0]] if not result_cedilha.empty else None,\n",
        "    'Uso inadequado hífen': result_hifen[result_hifen.columns[0]] if not result_hifen.empty else None,\n",
        "    'Espaço após parênteses': result_space_prts[result_space_prts.columns[0]] if not result_space_prts.empty else None,\n",
        "    'Espaços em excesso': result_excess_spaces_df[result_excess_spaces_df.columns[0]]if result_excess_spaces_df is not None and not result_excess_spaces_df[result_excess_spaces_df.columns[0]].empty else None\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#Transformando o dicionário em um dataframe.\n",
        "errors_df = pd.DataFrame({chave: valores for chave, valores in errors_dict.items() if valores is not None})\n",
        "errors_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yuRKznSk-eeS",
        "outputId": "9cdcb673-f5ba-40be-b8d0-e3fe0ef542b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Maiúscula após dois-pontos Espaço após parênteses  \\\n",
              "0    l\\nPublicado em:Tipos de te   línicos ( Turchioe e   \n",
              "1    \\nFigura 21.1: TExemplo de    l., 2022 ) . O domín   \n",
              "2    \\nFigura 21.2: ECorrelação    o tipos ( Matthiesse   \n",
              "3    \\nFigura 21.3: CSubstituiçã   Wu, 2008 ) . A Figur   \n",
              "4     por exemplo:\\nSExemplo de    precisa ( Jiang et a   \n",
              "..                           ...                    ...   \n",
              "295                          NaN                    NaN   \n",
              "296                          NaN                    NaN   \n",
              "297                          NaN                    NaN   \n",
              "298                          NaN                    NaN   \n",
              "299                          NaN                    NaN   \n",
              "\n",
              "            Espaços em excesso  \n",
              "0       tural - 21  PLN na Saú  \n",
              "1     eckbox\"] {\\n  width: 0.8  \n",
              "2     th: 0.8em;\\n  margin: 0   \n",
              "3    es/4556 */ \\n  vertical-a  \n",
              "4     sl-entry {\\n  clear: bot  \n",
              "..                         ...  \n",
              "295     });\\n    }\\n  }\\n});\\n  \n",
              "296                             \n",
              "297                             \n",
              "298            \\n       \\n      \n",
              "299            \\n       \\n      \n",
              "\n",
              "[300 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86ce8c7a-72a7-434a-82d5-367a935100c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Maiúscula após dois-pontos</th>\n",
              "      <th>Espaço após parênteses</th>\n",
              "      <th>Espaços em excesso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l\\nPublicado em:Tipos de te</td>\n",
              "      <td>línicos ( Turchioe e</td>\n",
              "      <td>tural - 21  PLN na Saú</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nFigura 21.1: TExemplo de</td>\n",
              "      <td>l., 2022 ) . O domín</td>\n",
              "      <td>eckbox\"] {\\n  width: 0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nFigura 21.2: ECorrelação</td>\n",
              "      <td>o tipos ( Matthiesse</td>\n",
              "      <td>th: 0.8em;\\n  margin: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nFigura 21.3: CSubstituiçã</td>\n",
              "      <td>Wu, 2008 ) . A Figur</td>\n",
              "      <td>es/4556 */ \\n  vertical-a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>por exemplo:\\nSExemplo de</td>\n",
              "      <td>precisa ( Jiang et a</td>\n",
              "      <td>sl-entry {\\n  clear: bot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>});\\n    }\\n  }\\n});\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\n       \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\n       \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86ce8c7a-72a7-434a-82d5-367a935100c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86ce8c7a-72a7-434a-82d5-367a935100c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86ce8c7a-72a7-434a-82d5-367a935100c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e8dd0fd-7084-4449-a450-67d3544041e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e8dd0fd-7084-4449-a450-67d3544041e7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e8dd0fd-7084-4449-a450-67d3544041e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Enviando resultado para arquivo\n",
        "\n",
        "if cap == cap04:\n",
        "  errors_df.to_csv('erros_capitulo_04.csv')\n",
        "elif cap == cap21:\n",
        "  errors_df.to_csv('erros_capitulo_21.csv')"
      ],
      "metadata": {
        "id": "knf_dbViRrK7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}